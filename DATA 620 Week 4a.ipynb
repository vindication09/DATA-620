{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment – High Frequency Words\n",
    "\n",
    "Group 4\n",
    "- Santosh Cheruku\n",
    "- Vinicio Haro\n",
    "- Javern Wilson\n",
    "- Saayed Alam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement \n",
    "\n",
    "1. Choose a corpus of interest.\n",
    "2. How many total unique words are in the corpus? (Please feel free to define unique words in any interesting,\n",
    "defensible way).\n",
    "3. Taking the most common words, how many unique words represent half of the total words in the corpus?\n",
    "4. Identify the 200 highest frequency words in this corpus.\n",
    "5. Create a graph that shows the relative frequency of these 200 words.\n",
    "6. Does the observed relative frequency of these words follow Zipf’s law? Explain.\n",
    "7. In what ways do you think the frequency of the words in this corpus differ from “all words in all corpora.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download required packages\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from urllib import request\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string as str\n",
    "from nltk.stem import PorterStemmer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Choose a Corpus of Interest\n",
    "\n",
    "Project Guttenberg is a site that allows you to read books directly from the HTML or as a standard txt file on the browser. Because of this, it is an ideal to use as a corpus because we do not need to download data locally. We can pull data directly from the URL thus making this work reproducible. \n",
    "\n",
    "For our corpus, we will be using the book BEALBY by H. G. Wells.\n",
    "\n",
    "http://www.gutenberg.org/files/59769/59769-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/files/59769/59769-0.txt\"\n",
    "\n",
    "response = request.urlopen(url)\n",
    "\n",
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning \n",
    "\n",
    "The raw text file contains the parts of the book that we do not want to use in our analysis. We do not want to use the publication page nor the chapters page. Thankfully we can impliment methodology to choose where and when to start reading the text into our notebook. \n",
    "\n",
    "We will also use the word_tokenize function to convert our raw text into a tokenized version.\n",
    "https://kite.com/python/docs/nltk.tokenize.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_position = raw.find(\"CHAPTER I\")\n",
    "\n",
    "ending_position = raw.find(\"End of the Project Gutenberg EBook of Bealby; A Holiday, by H. G. Wells\")\n",
    "\n",
    "raw = raw[starting_position:ending_position]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have converted the text into tokens, we want to look at the the number of words. In our case we have 83,914 tokenized words. Converting to tokens will make text operations much more efficient. It should be a data prep step when preparing raw data for some downstream analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How many total unique words are in the corpus? (Please feel free to define unique words in any interesting, defensible way)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we address the problem of unique words, we want to execute the best practice of cleaning the text data. One example why text should be cleaned is different tenses of the same word such as run and running. If we count them as unqie words, they would be counted as 2 but are they truly unique? No! They mean the same thing in different tenses. We accomplish this by removing the endings of words such as ing , ed, es, and so forth. \n",
    "\n",
    "Another text processing technique we want to use is to make every word lower case. Lets say we have the word \"start\" and somewhere else in the corpuse, we have \"Start.\" By definition, both words are unique because they ae different but in reality, they are the same word except one starts with upper case and the other starts with lower case. \n",
    "\n",
    "We are also going to remove numbers from the raw text. This is a common practice. We do not want to count numbers as words. We can easily do this by applying simple regular expression. \n",
    "\n",
    "Some of the other corpus processing techniques will be to remove whitespace and remove stopwords. \n",
    "\n",
    "We want to define unique words as words that are not stem versions of other words nor common stopwords. \n",
    "\n",
    "Sources:\n",
    "https://medium.com/@datamonsters/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/\n",
    "\n",
    "https://towardsdatascience.com/tfidf-for-piece-of-text-in-python-43feccaa74f8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9608"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tok = word_tokenize(raw)\n",
    "\n",
    "len(set(raw_tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 9,608 lines without doing anything to the raw text file data. After we convert words to tokens, we will only take alpha numeric words and make all words lower case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in raw_tok if w.isalpha()] #alphanumeric\n",
    "\n",
    "words = [w.lower() for w in words] #lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7686"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() #stemming (remove endings)\n",
    "\n",
    "stem = [ps.stem(w) for w in words]\n",
    "\n",
    "stem = set(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5450"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the text to some degree, we are able to count 5,450 unique words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Taking the most common words, how many unique words represent half of the total words in the corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a great opportunity to apply stop word removal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "stem2=[w for w in stem if w not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reconcil',\n",
       " 'estim',\n",
       " 'pay',\n",
       " 'tender',\n",
       " 'belli',\n",
       " 'cutter',\n",
       " 'void',\n",
       " 'imperfectli',\n",
       " 'bottl',\n",
       " 'invis',\n",
       " 'nightmar',\n",
       " 'frail',\n",
       " 'annoy',\n",
       " 'whiski',\n",
       " 'ors',\n",
       " 'unceremoni',\n",
       " 'brighter',\n",
       " 'learnt',\n",
       " 'disinterest',\n",
       " 'plump',\n",
       " 'wriggl',\n",
       " 'lowest',\n",
       " 'viril',\n",
       " 'hilari',\n",
       " 'foresight',\n",
       " 'toughish',\n",
       " 'fashion',\n",
       " 'secur',\n",
       " 'stop',\n",
       " 'snort',\n",
       " 'chop',\n",
       " 'start',\n",
       " 'vagu',\n",
       " 'cleanli',\n",
       " 'requir',\n",
       " 'excurs',\n",
       " 'half',\n",
       " 'stretcher',\n",
       " 'gypsi',\n",
       " 'calv',\n",
       " 'ditch',\n",
       " 'come',\n",
       " 'fifteen',\n",
       " 'purpl',\n",
       " 'publicli',\n",
       " 'etiquett',\n",
       " 'dew',\n",
       " 'en',\n",
       " 'solicitud',\n",
       " 'clearer',\n",
       " 'understand',\n",
       " 'policemen',\n",
       " 'sane',\n",
       " 'asphalt',\n",
       " 'tea',\n",
       " 'repeat',\n",
       " 'abil',\n",
       " 'estrordinari',\n",
       " 'overnight',\n",
       " 'invari',\n",
       " 'eb',\n",
       " 'forti',\n",
       " 'rapidli',\n",
       " 'plaster',\n",
       " 'flame',\n",
       " 'improv',\n",
       " 'footstep',\n",
       " 'doorstep',\n",
       " 'twelv',\n",
       " 'phrase',\n",
       " 'edward',\n",
       " 'shorncliff',\n",
       " 'paw',\n",
       " 'scar',\n",
       " 'daytim',\n",
       " 'machineri',\n",
       " 'suitabl',\n",
       " 'engin',\n",
       " 'newsi',\n",
       " 'carn',\n",
       " 'idiot',\n",
       " 'central',\n",
       " 'em',\n",
       " 'pot',\n",
       " 'subject',\n",
       " 'snooz',\n",
       " 'result',\n",
       " 'electr',\n",
       " 'proud',\n",
       " 'uman',\n",
       " 'verbal',\n",
       " 'writer',\n",
       " 'stark',\n",
       " 'presenc',\n",
       " 'somehow',\n",
       " 'redol',\n",
       " 'instead',\n",
       " 'strong',\n",
       " 'fact',\n",
       " 'chew',\n",
       " 'infest',\n",
       " 'darken',\n",
       " 'beribbon',\n",
       " 'tap',\n",
       " 'women',\n",
       " 'preoccup',\n",
       " 'orribl',\n",
       " 'unnam',\n",
       " 'brightli',\n",
       " 'shortest',\n",
       " 'chloroform',\n",
       " 'japanes',\n",
       " 'damag',\n",
       " 'recent',\n",
       " 'slightest',\n",
       " 'north',\n",
       " 'wait',\n",
       " 'fir',\n",
       " 'three',\n",
       " 'drew',\n",
       " 'ador',\n",
       " 'perspect',\n",
       " 'gape',\n",
       " 'lick',\n",
       " 'trivial',\n",
       " 'greedi',\n",
       " 'rude',\n",
       " 'splendour',\n",
       " 'coin',\n",
       " 'successor',\n",
       " 'patient',\n",
       " 'hear',\n",
       " 'barefac',\n",
       " 'vision',\n",
       " 'lengthen',\n",
       " 'brain',\n",
       " 'caddish',\n",
       " 'yellow',\n",
       " 'improp',\n",
       " 'slumber',\n",
       " 'suffici',\n",
       " 'note',\n",
       " 'compart',\n",
       " 'advis',\n",
       " 'scarlet',\n",
       " 'ireland',\n",
       " 'tear',\n",
       " 'gaswork',\n",
       " 'doria',\n",
       " 'van',\n",
       " 'replenish',\n",
       " 'overhead',\n",
       " 'dre',\n",
       " 'fri',\n",
       " 'restrict',\n",
       " 'peopl',\n",
       " 'american',\n",
       " 'pour',\n",
       " 'gather',\n",
       " 'illumin',\n",
       " 'attrit',\n",
       " 'scold',\n",
       " 'vouchsaf',\n",
       " 'prick',\n",
       " 'protect',\n",
       " 'regard',\n",
       " 'pewter',\n",
       " 'aghast',\n",
       " 'suppress',\n",
       " 'slowli',\n",
       " 'childish',\n",
       " 'liciou',\n",
       " 'seam',\n",
       " 'deal',\n",
       " 'delight',\n",
       " 'chat',\n",
       " 'cowsh',\n",
       " 'earliest',\n",
       " 'orchard',\n",
       " 'transcrib',\n",
       " 'applaud',\n",
       " 'untrustworthi',\n",
       " 'savag',\n",
       " 'excit',\n",
       " 'suppli',\n",
       " 'complain',\n",
       " 'rein',\n",
       " 'stove',\n",
       " 'pail',\n",
       " 'woolli',\n",
       " 'pale',\n",
       " 'dresser',\n",
       " 'militari',\n",
       " 'hopelessli',\n",
       " 'corner',\n",
       " 'went',\n",
       " 'wreath',\n",
       " 'confess',\n",
       " 'capac',\n",
       " 'syrian',\n",
       " 'enthusiasm',\n",
       " 'sicken',\n",
       " 'straightforward',\n",
       " 'trunk',\n",
       " 'smut',\n",
       " 'thur',\n",
       " 'volunt',\n",
       " 'pool',\n",
       " 'stare',\n",
       " 'meet',\n",
       " 'exchang',\n",
       " 'cypress',\n",
       " 'struggl',\n",
       " 'sorri',\n",
       " 'innumer',\n",
       " 'men',\n",
       " 'regular',\n",
       " 'hors',\n",
       " 'themselv',\n",
       " 'test',\n",
       " 'particular',\n",
       " 'fork',\n",
       " 'elud',\n",
       " 'lake',\n",
       " 'transpar',\n",
       " 'placid',\n",
       " 'represent',\n",
       " 'gust',\n",
       " 'action',\n",
       " 'spatterdash',\n",
       " 'checksammington',\n",
       " 'wan',\n",
       " 'eccentr',\n",
       " 'pepton',\n",
       " 'strung',\n",
       " 'lowli',\n",
       " 'welcom',\n",
       " 'frighten',\n",
       " 'alarm',\n",
       " 'surgeri',\n",
       " 'aros',\n",
       " 'rumpu',\n",
       " 'loss',\n",
       " 'meal',\n",
       " 'choic',\n",
       " 'creep',\n",
       " 'tart',\n",
       " 'harmoni',\n",
       " 'lad',\n",
       " 'halfpenni',\n",
       " 'examin',\n",
       " 'steal',\n",
       " 'sixti',\n",
       " 'waterloo',\n",
       " 'confid',\n",
       " 'kill',\n",
       " 'fat',\n",
       " 'horror',\n",
       " 'bath',\n",
       " 'sparkl',\n",
       " 'advanc',\n",
       " 'five',\n",
       " 'prevail',\n",
       " 'leader',\n",
       " 'knot',\n",
       " 'superimpos',\n",
       " 'nothin',\n",
       " 'cowardli',\n",
       " 'inform',\n",
       " 'malign',\n",
       " 'joylessli',\n",
       " 'assassin',\n",
       " 'baronetci',\n",
       " 'incivil',\n",
       " 'polish',\n",
       " 'mergleson',\n",
       " 'breathless',\n",
       " 'grief',\n",
       " 'perhap',\n",
       " 'neither',\n",
       " 'decent',\n",
       " 'mine',\n",
       " 'employ',\n",
       " 'saturday',\n",
       " 'laughter',\n",
       " 'superior',\n",
       " 'personag',\n",
       " 'repriev',\n",
       " 'attract',\n",
       " 'steel',\n",
       " 'accent',\n",
       " 'devot',\n",
       " 'green',\n",
       " 'butterfli',\n",
       " 'tricycl',\n",
       " 'damn',\n",
       " 'next',\n",
       " 'adorn',\n",
       " 'ting',\n",
       " 'tone',\n",
       " 'oili',\n",
       " 'apollinari',\n",
       " 'bulk',\n",
       " 'usual',\n",
       " 'milk',\n",
       " 'behaviour',\n",
       " 'quot',\n",
       " 'smilingli',\n",
       " 'backbon',\n",
       " 'gold',\n",
       " 'heard',\n",
       " 'wildli',\n",
       " 'nonsens',\n",
       " 'forbidden',\n",
       " 'avail',\n",
       " 'return',\n",
       " 'dexter',\n",
       " 'unabl',\n",
       " 'expand',\n",
       " 'holder',\n",
       " 'call',\n",
       " 'laggard',\n",
       " 'instruct',\n",
       " 'acknowledg',\n",
       " 'burn',\n",
       " 'stock',\n",
       " 'neg',\n",
       " 'lean',\n",
       " 'chair',\n",
       " 'relax',\n",
       " 'disorderli',\n",
       " 'abas',\n",
       " 'mode',\n",
       " 'gener',\n",
       " 'fight',\n",
       " 'explain',\n",
       " 'hurt',\n",
       " 'valley',\n",
       " 'caddi',\n",
       " 'post',\n",
       " 'convent',\n",
       " 'rug',\n",
       " 'blueness',\n",
       " 'toe',\n",
       " 'exhilar',\n",
       " 'polit',\n",
       " 'undress',\n",
       " 'lone',\n",
       " 'extraordinari',\n",
       " 'marmalad',\n",
       " 'rhododendra',\n",
       " 'mistook',\n",
       " 'sage',\n",
       " 'torn',\n",
       " 'chelsmor',\n",
       " 'privet',\n",
       " 'hire',\n",
       " 'discomfort',\n",
       " 'abruptli',\n",
       " 'snap',\n",
       " 'brew',\n",
       " 'interrupt',\n",
       " 'line',\n",
       " 'speaker',\n",
       " 'unev',\n",
       " 'bill',\n",
       " 'shape',\n",
       " 'atroci',\n",
       " 'battl',\n",
       " 'revel',\n",
       " 'inevit',\n",
       " 'someth',\n",
       " 'compar',\n",
       " 'dark',\n",
       " 'disinclin',\n",
       " 'slobber',\n",
       " 'patent',\n",
       " 'akimbo',\n",
       " 'godsend',\n",
       " 'thou',\n",
       " 'poltergeist',\n",
       " 'constabl',\n",
       " 'posit',\n",
       " 'fring',\n",
       " 'clearli',\n",
       " 'cock',\n",
       " 'leav',\n",
       " 'spike',\n",
       " 'achiev',\n",
       " 'hand',\n",
       " 'public',\n",
       " 'fur',\n",
       " 'delic',\n",
       " 'eyebrow',\n",
       " 'hospit',\n",
       " 'exquisit',\n",
       " 'later',\n",
       " 'inch',\n",
       " 'biographi',\n",
       " 'stale',\n",
       " 'trod',\n",
       " 'seventeen',\n",
       " 'squirrel',\n",
       " 'mum',\n",
       " 'dishabil',\n",
       " 'watch',\n",
       " 'lasso',\n",
       " 'wept',\n",
       " 'savouri',\n",
       " 'titl',\n",
       " 'doubt',\n",
       " 'marri',\n",
       " 'brast',\n",
       " 'slow',\n",
       " 'lengthi',\n",
       " 'flower',\n",
       " 'wiv',\n",
       " 'abov',\n",
       " 'rate',\n",
       " 'circlet',\n",
       " 'threw',\n",
       " 'handwash',\n",
       " 'enorm',\n",
       " 'consequ',\n",
       " 'unjust',\n",
       " 'vehem',\n",
       " 'mission',\n",
       " 'rehears',\n",
       " 'clap',\n",
       " 'wolv',\n",
       " 'gorgeou',\n",
       " 'throng',\n",
       " 'leisur',\n",
       " 'pantomim',\n",
       " 'bystand',\n",
       " 'elbow',\n",
       " 'bitter',\n",
       " 'meant',\n",
       " 'wake',\n",
       " 'jelli',\n",
       " 'dell',\n",
       " 'inspect',\n",
       " 'obscur',\n",
       " 'nois',\n",
       " 'jaw',\n",
       " 'dismiss',\n",
       " 'glut',\n",
       " 'much',\n",
       " 'luckiest',\n",
       " 'calmli',\n",
       " 'acr',\n",
       " 'predecessor',\n",
       " 'abandon',\n",
       " 'repack',\n",
       " 'sneer',\n",
       " 'jule',\n",
       " 'allus',\n",
       " 'wave',\n",
       " 'shin',\n",
       " 'burial',\n",
       " 'monosyllab',\n",
       " 'quicker',\n",
       " 'pencil',\n",
       " 'christian',\n",
       " 'suchlik',\n",
       " 'father',\n",
       " 'circu',\n",
       " 'univers',\n",
       " 'elucidatori',\n",
       " 'cambridg',\n",
       " 'speech',\n",
       " 'attend',\n",
       " 'chi',\n",
       " 'hen',\n",
       " 'honest',\n",
       " 'marvel',\n",
       " 'solitud',\n",
       " 'arm',\n",
       " 'finer',\n",
       " 'melancholi',\n",
       " 'satisfi',\n",
       " 'scart',\n",
       " 'villag',\n",
       " 'looper',\n",
       " 'ill',\n",
       " 'elabor',\n",
       " 'absentminded',\n",
       " 'recogn',\n",
       " 'snif',\n",
       " 'gross',\n",
       " 'lamb',\n",
       " 'imit',\n",
       " 'wire',\n",
       " 'freedom',\n",
       " 'spook',\n",
       " 'caus',\n",
       " 'reput',\n",
       " 'reaction',\n",
       " 'churlish',\n",
       " 'waistcoat',\n",
       " 'accord',\n",
       " 'policeman',\n",
       " 'gem',\n",
       " 'erbert',\n",
       " 'lumin',\n",
       " 'proof',\n",
       " 'calm',\n",
       " 'golf',\n",
       " 'dissip',\n",
       " 'sword',\n",
       " 'heavili',\n",
       " 'imposs',\n",
       " 'wink',\n",
       " 'destini',\n",
       " 'breakdown',\n",
       " 'older',\n",
       " 'exploratori',\n",
       " 'lunch',\n",
       " 'district',\n",
       " 'despond',\n",
       " 'lethargi',\n",
       " 'resort',\n",
       " 'sun',\n",
       " 'conqueror',\n",
       " 'concern',\n",
       " 'chain',\n",
       " 'eh',\n",
       " 'pretti',\n",
       " 'merit',\n",
       " 'appar',\n",
       " 'bond',\n",
       " 'church',\n",
       " 'primordi',\n",
       " 'odd',\n",
       " 'warm',\n",
       " 'due',\n",
       " 'side',\n",
       " 'mend',\n",
       " 'race',\n",
       " 'grappl',\n",
       " 'darlint',\n",
       " 'worship',\n",
       " 'window',\n",
       " 'ealth',\n",
       " 'upward',\n",
       " 'glow',\n",
       " 'picnic',\n",
       " 'cheapest',\n",
       " 'offer',\n",
       " 'train',\n",
       " 'sketch',\n",
       " 'obliqu',\n",
       " 'imself',\n",
       " 'deshabil',\n",
       " 'ostentati',\n",
       " 'warmth',\n",
       " 'differ',\n",
       " 'puzzl',\n",
       " 'ot',\n",
       " 'resent',\n",
       " 'trust',\n",
       " 'warili',\n",
       " 'highway',\n",
       " 'condescens',\n",
       " 'spoken',\n",
       " 'crinkl',\n",
       " 'march',\n",
       " 'weak',\n",
       " 'encamp',\n",
       " 'messag',\n",
       " 'abolish',\n",
       " 'undermin',\n",
       " 'possibl',\n",
       " 'swarm',\n",
       " 'earthli',\n",
       " 'thought',\n",
       " 'hard',\n",
       " 'annihil',\n",
       " 'coffe',\n",
       " 'hot',\n",
       " 'estrang',\n",
       " 'incomplet',\n",
       " 'nine',\n",
       " 'figur',\n",
       " 'confound',\n",
       " 'lectur',\n",
       " 'cray',\n",
       " 'cooker',\n",
       " 'amiabl',\n",
       " 'independ',\n",
       " 'substanti',\n",
       " 'ode',\n",
       " 'climax',\n",
       " 'applianc',\n",
       " 'theatric',\n",
       " 'let',\n",
       " 'crumpl',\n",
       " 'punch',\n",
       " 'butter',\n",
       " 'itali',\n",
       " 'tribe',\n",
       " 'liveli',\n",
       " 'hart',\n",
       " 'fix',\n",
       " 'influenza',\n",
       " 'marshi',\n",
       " 'bland',\n",
       " 'besieg',\n",
       " 'minist',\n",
       " 'chariti',\n",
       " 'ard',\n",
       " 'infami',\n",
       " 'cheek',\n",
       " 'divin',\n",
       " 'pillar',\n",
       " 'suspicion',\n",
       " 'remotest',\n",
       " 'lucid',\n",
       " 'precipit',\n",
       " 'prettiest',\n",
       " 'kindr',\n",
       " 'breez',\n",
       " 'border',\n",
       " 'flash',\n",
       " 'day',\n",
       " 'laugh',\n",
       " 'sunken',\n",
       " 'slept',\n",
       " 'tidier',\n",
       " 'master',\n",
       " 'urg',\n",
       " 'woodenhous',\n",
       " 'blackest',\n",
       " 'literatur',\n",
       " 'unexpectedli',\n",
       " 'waggishli',\n",
       " 'duologu',\n",
       " 'theme',\n",
       " 'hat',\n",
       " 'dot',\n",
       " 'british',\n",
       " 'blade',\n",
       " 'confabul',\n",
       " 'addit',\n",
       " 'notabl',\n",
       " 'explor',\n",
       " 'stand',\n",
       " 'festoon',\n",
       " 'modesti',\n",
       " 'hop',\n",
       " 'milkman',\n",
       " 'perform',\n",
       " 'commit',\n",
       " 'cave',\n",
       " 'verifi',\n",
       " 'feast',\n",
       " 'discuss',\n",
       " 'curt',\n",
       " 'rightli',\n",
       " 'massiv',\n",
       " 'boat',\n",
       " 'unpremedit',\n",
       " 'answer',\n",
       " 'stile',\n",
       " 'gallantri',\n",
       " 'extra',\n",
       " 'caravan',\n",
       " 'patch',\n",
       " 'furz',\n",
       " 'buzz',\n",
       " 'instant',\n",
       " 'cow',\n",
       " 'guardian',\n",
       " 'virgin',\n",
       " 'loud',\n",
       " 'absenc',\n",
       " 'assort',\n",
       " 'gate',\n",
       " 'tendenc',\n",
       " 'flank',\n",
       " 'stew',\n",
       " 'shaken',\n",
       " 'mistaken',\n",
       " 'stretch',\n",
       " 'flouri',\n",
       " 'gratifi',\n",
       " 'appear',\n",
       " 'leant',\n",
       " 'grave',\n",
       " 'begin',\n",
       " 'expos',\n",
       " 'chunk',\n",
       " 'tour',\n",
       " 'convinc',\n",
       " 'famou',\n",
       " 'punish',\n",
       " 'net',\n",
       " 'distinguish',\n",
       " 'lover',\n",
       " 'look',\n",
       " 'soundli',\n",
       " 'fowl',\n",
       " 'barrel',\n",
       " 'dispers',\n",
       " 'whose',\n",
       " 'detect',\n",
       " 'hardli',\n",
       " 'handi',\n",
       " 'outwardli',\n",
       " 'capabl',\n",
       " 'yourselv',\n",
       " 'oat',\n",
       " 'stimul',\n",
       " 'reproduc',\n",
       " 'mourn',\n",
       " 'shoulder',\n",
       " 'mite',\n",
       " 'idrophobia',\n",
       " 'upsettingli',\n",
       " 'gear',\n",
       " 'reproach',\n",
       " 'jewel',\n",
       " 'forgiv',\n",
       " 'abroad',\n",
       " 'occurr',\n",
       " 'parch',\n",
       " 'schock',\n",
       " 'sure',\n",
       " 'effect',\n",
       " 'drain',\n",
       " 'domain',\n",
       " 'newspap',\n",
       " 'trickster',\n",
       " 'fortun',\n",
       " 'lilac',\n",
       " 'sweetstuff',\n",
       " 'circumst',\n",
       " 'dessay',\n",
       " 'creak',\n",
       " 'dread',\n",
       " 'impercept',\n",
       " 'ordnanc',\n",
       " 'repudi',\n",
       " 'git',\n",
       " 'transvers',\n",
       " 'bodiless',\n",
       " 'case',\n",
       " 'beast',\n",
       " 'satisfactorili',\n",
       " 'paper',\n",
       " 'allow',\n",
       " 'chapel',\n",
       " 'testifi',\n",
       " 'focu',\n",
       " 'took',\n",
       " 'confront',\n",
       " 'arti',\n",
       " 'someon',\n",
       " 'shine',\n",
       " 'thrown',\n",
       " 'epilepsi',\n",
       " 'headlong',\n",
       " 'gaiter',\n",
       " 'teacher',\n",
       " 'streak',\n",
       " 'latent',\n",
       " 'herald',\n",
       " 'unt',\n",
       " 'friendship',\n",
       " 'contain',\n",
       " 'chal',\n",
       " 'artifici',\n",
       " 'rivulet',\n",
       " 'plank',\n",
       " 'revers',\n",
       " 'antiqu',\n",
       " 'disregard',\n",
       " 'rel',\n",
       " 'misfortun',\n",
       " 'deaf',\n",
       " 'contrast',\n",
       " 'fool',\n",
       " 'leviti',\n",
       " 'fortnight',\n",
       " 'spit',\n",
       " 'picturesqu',\n",
       " 'control',\n",
       " 'mighti',\n",
       " 'widow',\n",
       " 'hair',\n",
       " 'interlocutor',\n",
       " 'els',\n",
       " 'seri',\n",
       " 'materi',\n",
       " 'proffer',\n",
       " 'secret',\n",
       " 'sweet',\n",
       " 'backyard',\n",
       " 'heaven',\n",
       " 'beam',\n",
       " 'john',\n",
       " 'luck',\n",
       " 'ladyship',\n",
       " 'smaller',\n",
       " 'wold',\n",
       " 'share',\n",
       " 'spire',\n",
       " 'entir',\n",
       " 'grimac',\n",
       " 'farm',\n",
       " 'rib',\n",
       " 'omiss',\n",
       " 'broad',\n",
       " 'gladder',\n",
       " 'type',\n",
       " 'sweep',\n",
       " 'shout',\n",
       " 'norfic',\n",
       " 'mirror',\n",
       " 'landladi',\n",
       " 'scrutin',\n",
       " 'wha',\n",
       " 'tree',\n",
       " 'dozen',\n",
       " 'galleri',\n",
       " 'meek',\n",
       " 'mactaggart',\n",
       " 'incid',\n",
       " 'number',\n",
       " 'encount',\n",
       " 'sideway',\n",
       " 'imperson',\n",
       " 'telegraph',\n",
       " 'well',\n",
       " 'porth',\n",
       " 'maximum',\n",
       " 'sever',\n",
       " 'nose',\n",
       " 'street',\n",
       " 'desir',\n",
       " 'dudgeon',\n",
       " 'think',\n",
       " 'ladder',\n",
       " 'lord',\n",
       " 'hope',\n",
       " 'servil',\n",
       " 'nether',\n",
       " 'womanhood',\n",
       " 'woman',\n",
       " 'reconnoitr',\n",
       " 'percept',\n",
       " 'reclin',\n",
       " 'friendli',\n",
       " 'within',\n",
       " 'alcov',\n",
       " 'lark',\n",
       " 'sonor',\n",
       " 'unembarrass',\n",
       " 'especi',\n",
       " 'cockney',\n",
       " 'inanim',\n",
       " 'defect',\n",
       " 'customari',\n",
       " 'phase',\n",
       " 'urgent',\n",
       " 'term',\n",
       " 'tenanc',\n",
       " 'oughtn',\n",
       " 'kiss',\n",
       " 'length',\n",
       " 'massacr',\n",
       " 'rheim',\n",
       " 'portion',\n",
       " 'unobserv',\n",
       " 'numer',\n",
       " 'reveal',\n",
       " 'prove',\n",
       " 'seasid',\n",
       " 'whisper',\n",
       " 'common',\n",
       " 'counterbalanc',\n",
       " 'sustain',\n",
       " 'captain',\n",
       " 'period',\n",
       " 'consid',\n",
       " 'admir',\n",
       " 'scrap',\n",
       " 'ninth',\n",
       " 'alabast',\n",
       " 'effus',\n",
       " 'releg',\n",
       " 'cent',\n",
       " 'genuin',\n",
       " 'emit',\n",
       " 'mow',\n",
       " 'rake',\n",
       " 'carpet',\n",
       " 'ran',\n",
       " 'unfair',\n",
       " 'confirm',\n",
       " 'crowd',\n",
       " 'hanger',\n",
       " 'mutton',\n",
       " 'club',\n",
       " 'strewth',\n",
       " 'treacher',\n",
       " 'polic',\n",
       " 'imbecil',\n",
       " 'deceit',\n",
       " 'unless',\n",
       " 'perpetu',\n",
       " 'horticulturist',\n",
       " 'gamekeep',\n",
       " 'appal',\n",
       " 'festiv',\n",
       " 'handsom',\n",
       " 'remind',\n",
       " 'vii',\n",
       " 'reach',\n",
       " 'staircas',\n",
       " 'twenti',\n",
       " 'obstacl',\n",
       " 'charg',\n",
       " 'cat',\n",
       " 'practic',\n",
       " 'swim',\n",
       " 'thick',\n",
       " 'inferior',\n",
       " 'aviat',\n",
       " 'visit',\n",
       " 'occas',\n",
       " 'hawk',\n",
       " 'wednesday',\n",
       " 'suck',\n",
       " 'reduc',\n",
       " 'stem',\n",
       " 'nich',\n",
       " 'tactlessli',\n",
       " 'affect',\n",
       " 'seen',\n",
       " 'punctili',\n",
       " 'disord',\n",
       " 'dagger',\n",
       " 'tempter',\n",
       " 'depress',\n",
       " 'courag',\n",
       " 'wit',\n",
       " 'judici',\n",
       " 'knickerbock',\n",
       " 'thunder',\n",
       " 'quarri',\n",
       " 'calcul',\n",
       " 'thicket',\n",
       " 'chatter',\n",
       " 'dream',\n",
       " 'passag',\n",
       " 'waysid',\n",
       " 'deuc',\n",
       " 'soundest',\n",
       " 'burglari',\n",
       " 'vengeanc',\n",
       " 'brighten',\n",
       " 'rais',\n",
       " 'knive',\n",
       " 'charmingli',\n",
       " 'sedat',\n",
       " 'victim',\n",
       " 'hunt',\n",
       " 'jest',\n",
       " 'persuas',\n",
       " 'germ',\n",
       " 'girl',\n",
       " 'speci',\n",
       " 'curvatur',\n",
       " 'denud',\n",
       " 'farth',\n",
       " 'dissens',\n",
       " 'winni',\n",
       " 'abstemi',\n",
       " 'stepfath',\n",
       " 'centr',\n",
       " 'tussl',\n",
       " 'warn',\n",
       " 'advantag',\n",
       " 'cun',\n",
       " 'liber',\n",
       " 'laundri',\n",
       " 'togeth',\n",
       " 'command',\n",
       " 'allot',\n",
       " 'margin',\n",
       " 'gentlefolk',\n",
       " 'sway',\n",
       " 'said',\n",
       " 'asleep',\n",
       " 'pain',\n",
       " 'screever',\n",
       " 'jerkili',\n",
       " 'burglar',\n",
       " 'recept',\n",
       " ...]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
